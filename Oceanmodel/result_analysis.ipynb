{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv files to df\n",
    "# two parts because two batches\n",
    "simulation_result = pd.DataFrame()\n",
    "file_prefix = 'first_big_sim_batch_'\n",
    "\n",
    "batches = 90\n",
    "batch_size = 3\n",
    "\n",
    "for i in range(batches):\n",
    "    df = pd.read_csv('results/' + file_prefix + str(i) + '.csv')\n",
    "    df['subset'] = df['subset'] + i * batch_size\n",
    "\n",
    "    simulation_result = pd.concat([simulation_result, df])\n",
    "    \n",
    "file_prefix = 'first_big_sim_batch_small_'\n",
    "batches = 324\n",
    "batches_start = 271\n",
    "batch_size = 1\n",
    "\n",
    "for i in range(batches_start, batches):\n",
    "    df = pd.read_csv('results/' + file_prefix + str(i) + '.csv')\n",
    "    df['subset'] = df['subset'] + i * batch_size\n",
    "\n",
    "    simulation_result = pd.concat([simulation_result, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate system_params\n",
    "system_params = create_par_sweep(system_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might be inverse? ~\n",
    "df_kpi = simulation_result.groupby(['subset']).apply(lambda x: (x.Agg_APY < 0.05).any())\n",
    "\n",
    "# join with params\n",
    "df_kpi = df_kpi.reset_index()\n",
    "# for every row of df_kpi, join column='key' with values system_params[key][x['subset']] \n",
    "for key in system_params.keys():\n",
    "    df_kpi = df_kpi.join(df_kpi.apply(lambda x: system_params[key][x['subset']], axis = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_success(X, Y, name):\n",
    "    print(\"-\"*50)\n",
    "    print(\"KPI: {}\".format(name))\n",
    "    print(\"-\"*50)\n",
    "    print()\n",
    "    print()\n",
    "    # Fit model\n",
    "    model = sm.Logit(Y, X).fit()\n",
    "    \n",
    "    # Find predictors\n",
    "    predictors = pd.concat([model.params, model.pvalues], axis=1)\n",
    "    predictors.columns = ['coef', 'p-value']\n",
    "    predictors = predictors.drop(index='const')\n",
    "    predictors = predictors[predictors['p-value'] < .05]\n",
    "    print(\"Statistically Significant Predictors (Logistic Regression):\")\n",
    "    print(predictors)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2,\n",
    "                             figsize=(15, 12),\n",
    "                             gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "    rf = RandomForestClassifier(max_depth=6)\n",
    "    model.fit(X, Y)\n",
    "    rf.fit(X, Y)\n",
    "\n",
    "    importance = (pd.DataFrame(list(zip(rf.feature_names_in_, rf.feature_importances_)),\n",
    "                           columns=['features', 'importance'])\n",
    "              .sort_values(by='importance', ascending=False)\n",
    "              )\n",
    "\n",
    "    plot_tree(model,\n",
    "                  rounded=True,\n",
    "                  proportion=True,\n",
    "                  fontsize=8,\n",
    "                  feature_names=X.columns,\n",
    "                  class_names=['Failure', 'Success'],\n",
    "                  filled=True,\n",
    "                  ax=axes[0])\n",
    "\n",
    "    axes[0].set_title(\n",
    "            f'Decision tree, score: {model.score(X, Y) :.0%}. N: {len(X) :.2e}')\n",
    "    sns.barplot(data=importance,\n",
    "                    x=importance.features,\n",
    "                    y=importance.importance,\n",
    "                    ax=axes[1],\n",
    "                    label='small')\n",
    "    plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=45)\n",
    "    axes[1].set_title(f'Feature Importance')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    variables = [a for a in X.columns if a != \"const\"]\n",
    "    fig, axs = plt.subplots(nrows = 4, ncols = 4, figsize=(20,20))\n",
    "    for i, var in enumerate(variables):\n",
    "        ax = axs[i // 4, i%4]\n",
    "        sns.kdeplot(kpis, x=var, hue=y, ax=ax, common_norm=False,\n",
    "                   common_grid=False)\n",
    "        ax.set_title(\"{} KDE by Success\".format(var))\n",
    "    plt.show()\n",
    "    \n",
    "    for _ in range(20):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kpis[['weekly_lock_prob','weekly_vote_success_prob','weekly_consume_multiple']]\n",
    "\n",
    "# Scale to standard normal\n",
    "X = (X - X.mean()) / X.std()\n",
    "X['const'] = 1\n",
    "\n",
    "y = ['Agg_APY']\n",
    "Y = df_kpi[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_success(X, Y, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
